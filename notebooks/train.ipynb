{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2923f819-6419-469e-a9ad-3a8cc7554e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a999d295-e7b6-467f-b6f9-9b020ade423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train_config, model_config, tokenizer_config):\n",
    "\n",
    "    device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f'Using device: {device}')\n",
    "\n",
    "    dls_and_tokenizers_dict = get_loaders_and_tokenizers(tokenizer_config, raw_dataset)\n",
    "    src_tokenizer = dls_and_tokenizers_dict['src_tokenizer']\n",
    "    tagret_tokenizer = dls_and_tokenizers_dict['target_tokenizer']\n",
    "    \n",
    "    model = make_transformer(model_config).to(device) # TODO: create the config for the model.\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=train_config['lr'])\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=src_tokenizer.token_to_id('[PAD]'), label_smoothing=0.1).to(device)\n",
    "\n",
    "    for epoch in range(train_config['epochs']):\n",
    "        train_dl = tqdm(dls_and_tokenizers_dict['train_dl'], desc=f'Processing epoch: {epoch:02d}')\n",
    "        for batch in train_dl:\n",
    "            encoder_inputs = batch['encoder_inputs'].to(device)\n",
    "            decoder_inputs = batch['decoder_inputs'].to(device)\n",
    "            encoder_mask = batch['encoder_mask'].to(device)\n",
    "            decoder_mask = batch['decoder_mask'].to(device)\n",
    "            label = batch['label'].to(device)\n",
    "\n",
    "            encoder_outputs = model.encode(encoder_inputs, encoder_mask)\n",
    "            decoder_outputs = model.decode(encoder_outputs, encoder_mask, decoder_inputs, decoder_mask)\n",
    "            model_outputs = model.generate(decoder_outputs)\n",
    "\n",
    "            loss = loss_fn(model_outputs.view(-1, tagret_tokenizer.get_vocab_size()), label.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_dl.set_postfix({'loss': f'{loss.item():6.3f}'})\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541c4901-e070-4773-8234-f18305f046f9",
   "metadata": {},
   "outputs": [],
   "source": [
    " {'encoder_inputs': encoder_inputs,\n",
    "                'decoder_inputs': decoder_inputs,\n",
    "                'label': label,\n",
    "                'encoder_mask': ((encoder_inputs != self.pad_token)[None:, ...][None:, ...]).int(),\n",
    "                'decoder_mask': (decoder_inputs != self.pad_token[None:, ...][None:, ...]).int() & causal_mask(sel.model_max_length),\n",
    "                'src_text': src_text,\n",
    "                'tgt_text': tgt_text\n",
    "               }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
